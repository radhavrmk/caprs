{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(palette=\"magma_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. top_100_brands(brandname+syn',\n",
       " '2. reference_color',\n",
       " '3. personalization_rules(exampl',\n",
       " '4. sample_occasion',\n",
       " '5. influencer_color_rules',\n",
       " '6. category_and_subcategory',\n",
       " '7. user_subset',\n",
       " '8. item_subset',\n",
       " '9. category_ids',\n",
       " '10. brands_affinity',\n",
       " '11. styling_segments',\n",
       " '12. wishlist_items',\n",
       " '13. user_influencer',\n",
       " '14. 100_users_set',\n",
       " '15. 100_users_item_set',\n",
       " '16. 100_user_influencer']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile('../../data/raw/mar19.xlsx')\n",
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to avoid hardcoding of sheet names which might change later\n",
    "top_brands_sheet = \"1. top_100_brands(brandname+syn\"\n",
    "category_sheet = \"9. category_ids\"\n",
    "user_sheet = \"14. 100_users_set\"\n",
    "items_sheet = \"15. 100_users_item_set\"\n",
    "wishlist_sheet = \"12. wishlist_items\"\n",
    "influencer_sheet = \"16. 100_user_influencer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Category ID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Category ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tops</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blouses</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T Shirts</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanks</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knits</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category Name  Category ID\n",
       "0          Tops          110\n",
       "1       Blouses          111\n",
       "2      T Shirts          112\n",
       "3         Tanks          113\n",
       "4         Knits          114"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = xlsx.parse(category_sheet)\n",
    "\n",
    "df_cat.dropna(inplace=True)\n",
    "df_cat[\"Category ID\"] = df_cat[\"Category ID\"].astype(\"int64\")\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load unique brandID strings for top brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71            madewell\n",
       "116    victoriassecret\n",
       "24            colehaan\n",
       "7            anntaylor\n",
       "112               vans\n",
       "43           hollister\n",
       "104               toms\n",
       "29           dolcevita\n",
       "114               vici\n",
       "96           stelladot\n",
       "113              venus\n",
       "120        warbyparker\n",
       "103               tobi\n",
       "13      bananarepublic\n",
       "70               lulus\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topbrands = xlsx.parse(top_brands_sheet)\n",
    "df_topbrands = df_topbrands[\"brand_name\"].append(df_topbrands[\"brand_name_synonym\"]).map(lambda x : \"\".join(x.split()).lower()).drop_duplicates().sort_values().reset_index(drop=True)\n",
    "df_topbrands.sample(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load influencer data to attach to users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencers = [\n",
    "    \"ariellecharnas\",\n",
    "    \"blaireadiebee\",\n",
    "    \"blakevond\",\n",
    "    \"chiaraferragni\",\n",
    "    \"hannahbronfman\",\n",
    "    \"jordynwoods\",\n",
    "    \"manrepeller\",\n",
    "    \"mayemusk\",\n",
    "    \"nicolettemason\",\n",
    "    \"seaofshoes\",\n",
    "    \"somethingnavy\",\n",
    "    \"weworewhat\"\n",
    "]\n",
    "\n",
    "df_influencers = xlsx.parse(influencer_sheet)\n",
    "df_influencers[\"user_id\"] = df_influencers[\"user_id\"].map(lambda x : x[-13:])\n",
    "df_influencers[\"influencers\"] = df_influencers[\"style_who_inspiries\"].map(lambda x : [1 if re.search(i,x) else 0 for i in influencers ])\n",
    "df_influencers[influencers] = pd.DataFrame(df_influencers[\"influencers\"].values.tolist(), index = df_influencers.index)\n",
    "df_influencers.drop([\"style_who_inspiries\", \"influencers\"], axis =1, inplace=True)\n",
    "df_influencers.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_influencers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = xlsx.parse(user_sheet)\n",
    "\n",
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = xlsx.parse(user_sheet)\n",
    "\n",
    "user_fields = [\n",
    "    \"user_id\",\n",
    "    \"style_age_range\",\n",
    "    \"style_age_range_group\",\n",
    "    \"items_in_wishlist\",\n",
    "    \"style_brands_selected\",\n",
    "    \"style_size_preference_none\",\n",
    "    \"style_size_preference_petite\",\n",
    "    \"style_size_preference_extra_long\",\n",
    "    \"style_size_preference_plus\",\n",
    "    \"style_size_preference_maternity\",\n",
    "    \"style_size_preference_skipped\",\n",
    "    \"style_vibe\",\n",
    "    \"has_stype_vibe\",\n",
    "    \"style_who_inspiries_skipped\",\n",
    "    \"style_looks_wanted_dates\",\n",
    "    \"style_looks_wanted_everyday\",\n",
    "    \"style_looks_wanted_formal\",\n",
    "    \"style_looks_wanted_nights\",\n",
    "    \"style_looks_wanted_other\",\n",
    "    \"style_looks_wanted_summer\",\n",
    "    \"style_looks_wanted_travel\",\n",
    "    'style_looks_wanted_winter',\n",
    "    \"style_looks_wanted_work\",\n",
    "    \"style_looks_wanted_workouts\",\n",
    "    \"style_looks_wanted_skipped\",\n",
    "    'style_most_important_active', \n",
    "    'style_most_important_any',\n",
    "    'style_most_important_beach', \n",
    "    'style_most_important_dress',\n",
    "    'style_most_important_bags', \n",
    "    'style_most_important_jeans',\n",
    "    'style_most_important_jump', \n",
    "    'style_most_important_nothing',\n",
    "    'style_most_important_outwear', \n",
    "    'style_most_important_pants',\n",
    "    'style_most_important_shoes', \n",
    "    'style_most_important_tops',\n",
    "    'style_most_important_skipped'\n",
    "    ]\n",
    "\n",
    "df_users = df_users[user_fields]\n",
    "df_users[\"user_id\"] = df_users[\"user_id\"].map(lambda x : x[-13:])\n",
    "df_users[\"style_age_range_group\"] = df_users[\"style_age_range_group\"].fillna(5)\n",
    "df_users[\"style_vibe\"] = df_users[\"style_vibe\"].fillna(\"None\")\n",
    "\n",
    "user_fillna_zero_columns = [\n",
    "    \"style_size_preference_none\",\n",
    "    \"style_size_preference_petite\",\n",
    "    \"style_size_preference_extra_long\",\n",
    "    \"style_size_preference_plus\",\n",
    "    \"style_size_preference_maternity\",\n",
    "    \"style_looks_wanted_dates\",\n",
    "    \"style_looks_wanted_everyday\",\n",
    "    \"style_looks_wanted_formal\",\n",
    "    \"style_looks_wanted_nights\",\n",
    "    \"style_looks_wanted_other\",\n",
    "    \"style_looks_wanted_summer\",\n",
    "    \"style_looks_wanted_travel\",\n",
    "    'style_looks_wanted_winter',\n",
    "    \"style_looks_wanted_work\",\n",
    "    \"style_looks_wanted_workouts\",\n",
    "    'style_most_important_active', \n",
    "    'style_most_important_any',\n",
    "    'style_most_important_beach', \n",
    "    'style_most_important_dress',\n",
    "    'style_most_important_bags', \n",
    "    'style_most_important_jeans',\n",
    "    'style_most_important_jump', \n",
    "    'style_most_important_nothing',\n",
    "    'style_most_important_outwear', \n",
    "    'style_most_important_pants',\n",
    "    'style_most_important_shoes', \n",
    "    'style_most_important_tops',\n",
    "    'style_most_important_skipped'\n",
    "]\n",
    "df_users[user_fillna_zero_columns] = df_users[user_fillna_zero_columns].fillna(0)\n",
    "\n",
    "user_drop_columns = [\n",
    "    \"style_age_range\",\n",
    "    \"style_brands_selected\",\n",
    "    \"has_stype_vibe\",\n",
    "    \"style_who_inspiries_skipped\",\n",
    "    \"items_in_wishlist\"\n",
    "]\n",
    "df_users.drop(user_drop_columns, axis=1, inplace=True)\n",
    "\n",
    "user_int_conversion_columns = [\n",
    "    \"style_age_range_group\",\n",
    "    \"style_size_preference_none\",\n",
    "    \"style_size_preference_petite\",\n",
    "    \"style_size_preference_extra_long\",\n",
    "    \"style_size_preference_plus\",\n",
    "    \"style_size_preference_maternity\",\n",
    "    \"style_size_preference_skipped\",\n",
    "    \"style_looks_wanted_dates\",\n",
    "    \"style_looks_wanted_everyday\",\n",
    "    \"style_looks_wanted_formal\",\n",
    "    \"style_looks_wanted_nights\",\n",
    "    \"style_looks_wanted_other\",\n",
    "    \"style_looks_wanted_summer\",\n",
    "    \"style_looks_wanted_travel\",\n",
    "    'style_looks_wanted_winter',\n",
    "    \"style_looks_wanted_work\",\n",
    "    \"style_looks_wanted_workouts\",\n",
    "    \"style_looks_wanted_skipped\",\n",
    "    'style_most_important_active', \n",
    "    'style_most_important_any',\n",
    "    'style_most_important_beach', \n",
    "    'style_most_important_dress',\n",
    "    'style_most_important_bags', \n",
    "    'style_most_important_jeans',\n",
    "    'style_most_important_jump', \n",
    "    'style_most_important_nothing',\n",
    "    'style_most_important_outwear', \n",
    "    'style_most_important_pants',\n",
    "    'style_most_important_shoes', \n",
    "    'style_most_important_tops',\n",
    "    'style_most_important_skipped'\n",
    "]\n",
    "df_users[user_int_conversion_columns] = df_users[user_int_conversion_columns].astype(\"int64\")\n",
    "\n",
    "\n",
    "df_users = pd.merge(df_users,df_influencers,left_on=\"user_id\",right_on=\"user_id\", how=\"left\")\n",
    "df_users[influencers] = df_users[influencers].fillna(0).astype(\"int64\")\n",
    "df_users.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This is a concern to be addressed \"\"\"\n",
    "\n",
    "df_users.duplicated(df_users.columns[1:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Style vibe hardly repeats (about 6). Having so many values will throw the model off once numeric encoded, \n",
    "as there is not enough repetition across observations \n",
    "This column in current state is not worth cleaning \n",
    "\"\"\"\n",
    "df_users.style_vibe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.drop(\"style_vibe\", inplace=True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "style_looks wanted columns seem interesting, but useless as none of the users have any data.\n",
    "The best we can possibly do here is to impute \n",
    "\"\"\"\n",
    "\n",
    "for i in df_users.columns[1:]:\n",
    "    temp = df_users[i].value_counts().reset_index()\n",
    "    sns.countplot(x=i,  data=df_users)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "placeholder to impute style looks wanted columns\n",
    "for now drop the columns\n",
    "\"\"\"\n",
    "\n",
    "style_looks_columns = [\n",
    "    \"style_looks_wanted_dates\",\n",
    "    \"style_looks_wanted_everyday\",\n",
    "    \"style_looks_wanted_formal\",\n",
    "    \"style_looks_wanted_nights\",\n",
    "    \"style_looks_wanted_other\",\n",
    "    \"style_looks_wanted_summer\",\n",
    "    \"style_looks_wanted_travel\",\n",
    "    'style_looks_wanted_winter',\n",
    "    \"style_looks_wanted_work\",\n",
    "    \"style_looks_wanted_workouts\",\n",
    "] \n",
    "\n",
    "df_users.drop(style_looks_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write dataframe to CSV file\n",
    "df_users.to_csv(\"../..//data/processed/users.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_columns_tokeep = [\n",
    "        'user_id', 'brand_id', 'user_provided_brand_name', 'parsed_brand_name',\n",
    "        'store_id', 'user_provided_store_name','parsed_store_name','product_id', \n",
    "        'item_name_lower', 'product_category_id', 'paid_price',\n",
    "        'list_price', 'sale_price',\n",
    "        'order_total_amt', 'size', 'email_dt', 'color_parsed']\n",
    "\n",
    "\"\"\" usecols not working. Seems to be a bug\"\"\"\n",
    "df_items = xlsx.parse(items_sheet)\n",
    "df_items = df_items[item_columns_tokeep]\n",
    "\n",
    "\n",
    "df_items[\"user_id\"] = df_items[\"user_id\"].map(lambda x : x[-13:])\n",
    "\n",
    "##Dropping rows with null product ID\n",
    "df_items = df_items[~df_items[\"product_id\"].isnull()]\n",
    "df_items[\"product_id\"] = df_items[\"product_id\"].map(lambda x : x[-8:])\n",
    "\n",
    "\n",
    "\n",
    "df_items[\"product_category_id\"].fillna(0, inplace=True)\n",
    "df_items[\"product_category_id\"] = df_items[\"product_category_id\"].astype(\"int64\")\n",
    "\n",
    "\n",
    "##Adding \"on sale\" column indicate a purchase of item in sale \n",
    "df_items[\"on_sale\"] = df_items[\"sale_price\"].map(lambda x : True if x > 0 else False)\n",
    "df_items[\"part_of_order\"] = df_items.apply(lambda x : True if x[\"order_total_amt\"] > x[\"paid_price\"] else False, axis=1)\n",
    "\n",
    "##Get brand id with blank from other two brand columns when avaialble, else set to None\n",
    "condition = pd.isnull(df_items[\"brand_id\"])\n",
    "df_items.loc[condition,\"brand_id\"] = df_items.loc[condition,\"parsed_brand_name\"]\n",
    "condition = pd.isnull(df_items[\"brand_id\"])\n",
    "df_items.loc[condition,\"brand_id\"] = df_items.loc[condition,\"user_provided_brand_name\"]\n",
    "condition = pd.notnull(df_items[\"brand_id\"])\n",
    "df_items.loc[condition,\"brand_id\"] = df_items.loc[condition,\"brand_id\"].map(lambda x : \"\".join(x.split()).lower())\n",
    "\n",
    "df_items[\"brand_id\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "##Get store id with blank from other two brand columns when avaialble, else set to None\n",
    "condition = pd.isnull(df_items[\"store_id\"])\n",
    "df_items.loc[condition,\"store_id\"] = df_items.loc[condition,\"parsed_store_name\"]\n",
    "condition = pd.isnull(df_items[\"store_id\"])\n",
    "df_items.loc[condition,\"store_id\"] = df_items.loc[condition,\"user_provided_store_name\"]\n",
    "condition = pd.notnull(df_items[\"brand_id\"])\n",
    "df_items.loc[condition,\"store_id\"] = df_items.loc[condition,\"store_id\"].map(lambda x : \"\".join(x.split()).lower())\n",
    "\n",
    "##Set store id ro Brand ID when null\n",
    "condition = pd.isnull(df_items[\"store_id\"])\n",
    "df_items.loc[condition,\"store_id\"] = df_items.loc[condition,\"brand_id\"]\n",
    "\n",
    "## Set store ID to none if still not available\n",
    "df_items[\"store_id\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "df_items[\"top_brand\"] = df_items[\"store_id\"].map(lambda x : True if x in df_topbrands.values.tolist() else False )\n",
    "\n",
    "\n",
    "item_drop_columns = [\n",
    "    \"sale_price\",\n",
    "    \"order_total_amt\",\n",
    "    \"user_provided_brand_name\",\n",
    "    \"parsed_brand_name\",\n",
    "    \"user_provided_store_name\",\n",
    "    \"parsed_store_name\"\n",
    "]\n",
    "df_items.drop(item_drop_columns, axis = 1,inplace=True)\n",
    "\n",
    "\n",
    "df_items.sample(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Seems like this part of order column can be dropped\"\"\"\n",
    "df_items.part_of_order.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Leave on sale as is for now\"\"\"\n",
    "df_items.on_sale.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Category ID have lot of in correct values. Drop the rows with category ID that is not present in master list\"\"\"\n",
    "df_items.product_category_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df_items.product_category_id.map( lambda x : x in df_cat[\"Category ID\"].values.tolist())\n",
    "df_items = df_items[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "g = sns.countplot(df_items.product_category_id)\n",
    "loc, labels = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_cats = (df_items.product_category_id//100)*100\n",
    "plt.figure(figsize=(8,8))\n",
    "g = sns.countplot(major_cats)\n",
    "loc, labels = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wishlist_columns_tokeep = [\n",
    "    \n",
    "]\n",
    "df_wish = xlsx.parse(wishlist_sheet)\n",
    "df_wish[\"user_id\"] = df_wish[\"userid\"].map(lambda x : x[-13:])\n",
    "df_wish[\"product_id\"] = df_wish[\"itemid\"].map(lambda x : x[-8:])\n",
    "\n",
    "wish_drop_columns = [\n",
    "    \"userid\", \"itemid\"\n",
    "]\n",
    "df_wish.drop(wish_drop_columns, axis=1, inplace=True)\n",
    "\n",
    "df_wish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_items.brand_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_items.store_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
