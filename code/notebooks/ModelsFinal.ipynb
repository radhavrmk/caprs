{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise\n",
    "# !conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import re\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from scipy.stats import randint\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "\n",
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from surprise import KNNBasic, KNNBaseline, KNNWithZScore, KNNWithMeans\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_products(df_items):\n",
    "    print(\"\\nGenerate unique products dataframe ...\\n\")\n",
    "    products =df_items.copy()\n",
    "    products.columns\n",
    "    products.drop([\"user_id\",\"store_id\",\"paid_price\",\"part_of_order\",\"top_brand\",\"color\", \"Category Name\"],axis=1, inplace=True)\n",
    "    products.drop_duplicates(subset=\"product_id\", inplace=True)\n",
    "    print(products.head())\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function creates a sparse matrix and a simple group by for user - product combinations\n",
    "When store_cat is set to True, it uses product category and store as proxy for product \n",
    "Note : change this to create sparse matrices instead of returning pandas dataframes\n",
    "\"\"\"\n",
    "def get_user_prod_matrix(df, store_cat = True):\n",
    "    df_items[\"store_cat\"] = df_items.apply(lambda x : x[\"store_id\"] + \" - \"+ str(x[\"product_category_id\"]), axis=1)\n",
    "    \n",
    "    if store_cat:\n",
    "        sparse = pd.pivot_table(df_items, index=\"user_id\", columns=\"store_cat\", values=\"product_id\", aggfunc=\"count\")\n",
    "    else:\n",
    "        sparse = pd.crosstab(index = df_items[\"user_id\"], columns = df_items[\"product_id\"], values=\"product_id\", aggfunc=\"count\")\n",
    "    \n",
    "    grp = sparse.stack().dropna().reset_index()       \n",
    "    grp = grp.rename(columns={0:\"rating\"} )\n",
    "\n",
    "    if store_cat:\n",
    "        grp = grp.rename(columns = {\"store_cat\": \"product_id\"})\n",
    "\n",
    "\n",
    "    return (grp, sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interaction_files(items_data):\n",
    "\n",
    "    print(\"\\nGenerate interaction: user vs store-cat and user vs products...\\n\")\n",
    "    x1, y1 = get_user_prod_matrix(items_data)\n",
    "    x2, y2 = get_user_prod_matrix(items_data, False)\n",
    "    # unique_user_sample = x2.user_id.sample(5).values.tolist()\n",
    "    # print(unique_user_sample)\n",
    "\n",
    "    x1[\"base\"] = \"store_cat\"\n",
    "    x2[\"base\"] = \"product\"\n",
    "\n",
    "    full_ratings = x1.append(x2).reset_index(drop=True)\n",
    "    full_ratings.to_csv(\"../..//data/processed/all_ratings.csv\",index=False)\n",
    "    x1.drop(\"base\", axis=1, inplace=True)\n",
    "    x2.drop(\"base\", axis=1, inplace=True) \n",
    "    return (x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_products(uid, df, n_count=10):\n",
    "    cols_tokeep = [\"product_id\", \"brand_id\", \"product_category_id\", \"rating\",\"price_bin\", \"item_name_lower\"]   \n",
    "    col_names = [\"Product ID\", \"Brand\", \"Category\", \"Times Bought\",\"Price Bin\", \"Descr\"]   \n",
    "\n",
    "\n",
    "    user_products = df[df.user_id==uid]\n",
    "    count = min(user_products.shape[0], n_count)\n",
    "    user_top_products = user_products.sort_values(\"rating\",ascending=False).head(count).merge(products, on=\"product_id\")[cols_tokeep] \n",
    "    user_top_products.columns = col_names\n",
    "    return user_top_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_storecats(uid, df, n_count=10):\n",
    "    cols_tokeep = [\"product_id\", \"rating\"]   \n",
    "    col_names = [\"Store - Category\", \"Times Bought\"]   \n",
    "\n",
    "\n",
    "    user_products = df[df.user_id==uid]\n",
    "    count = min(user_products.shape[0], n_count)\n",
    "    user_top_products = user_products.sort_values(\"rating\",ascending=False).head(count)[cols_tokeep]\n",
    "    user_top_products.columns = col_names\n",
    "    return user_top_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_recommendations(user_id, scores, n_recommendations=7):\n",
    "    scores = scores[scores.uid == user_id]\n",
    "    count = min(scores.shape[0], n_recommendations)\n",
    "    cols_tokeep = [\"est\", \"product_id\", \"brand_id\", \"product_category_id\", \"price_bin\", \"item_name_lower\" ]\n",
    "    col_names = [\"Rating Estimate\", \"Product ID\", \"Brand\", \"Category\", \"Price Bin\", \"Descr\"]\n",
    "    temp_df = scores.sort_values(\"est\", ascending=False).head(count).rename(columns={\"iid\":\"product_id\"}).merge(products, on=\"product_id\")[cols_tokeep]\n",
    "    temp_df.columns = col_names\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_recommendations_cat(user_id, scores, n_recommendations=7):\n",
    "    scores = scores[scores.uid == user_id]\n",
    "    count = min(scores.shape[0], n_recommendations)\n",
    "    cols_tokeep = [\"est\", \"iid\"]\n",
    "    col_names = [\"Rating Estimate\", \"Store - Category\"]\n",
    "    temp_df = scores.sort_values(\"est\", ascending=False).head(count)[cols_tokeep]\n",
    "    temp_df.columns = col_names\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSurpriseModel(data, base, algo=SVD, search_iteration = 2):\n",
    "    \n",
    "    print(f\"\\n****** Training for Surprise model: {algo.__name__} with {base} data ...\\n\")\n",
    "    \n",
    "    KNN_based = [KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline]\n",
    "    SVD_based = [SVD, SVDpp]\n",
    "    \n",
    "    if (algo in SVD_based):\n",
    "        param_grid = {\n",
    "            'n_factors': [5,10,15,20],\n",
    "            'n_epochs': [10, 20, 40, 80], \n",
    "            'lr_all': np.linspace(1e-4,2e-1,200),\n",
    "            'reg_all': np.linspace(0,1,100),\n",
    "            'random_state':[35]\n",
    "        }\n",
    "    \n",
    "    if (algo == NMF):\n",
    "        param_grid = {\n",
    "            'n_factors': [5,10,15,20],\n",
    "            'n_epochs': [10, 20, 40, 80], \n",
    "            'random_state':[35]\n",
    "        }\n",
    "\n",
    "    if (algo in KNN_based):\n",
    "        param_grid = {\n",
    "            'k': [1,3,5,10,15,20,25,30,35,40,45,50],\n",
    "            'sim_options': {\n",
    "                'name': ['msd', 'cosine'],\n",
    "                'min_support': [1,3,5,10,15,20,25,30,35,40,45,50],\n",
    "                'user_based': [False, True]},\n",
    "            }\n",
    "       \n",
    "    #print(param_grid)\n",
    "    gs = RandomizedSearchCV(algo, param_grid, measures=['rmse', 'mae'], cv=3, refit=True,n_jobs=-1, n_iter=search_iteration)\n",
    "    gs.fit(data)\n",
    "\n",
    "    # best RMSE score\n",
    "    print(f\"best RMSE score : {gs.best_score['rmse']}\")\n",
    "    print(f\"best MAE score : {gs.best_score['mae']}\")\n",
    "\n",
    "    # combination of parameters that gave the best RMSE score\n",
    "    print(f\"best parms for RMSE score : {gs.best_params['rmse']}\")\n",
    "    print(f\"best parms for MAE score : {gs.best_params['mae']}\")\n",
    "\n",
    "    train_set = data.build_full_trainset()\n",
    "    all_set = train_set.build_testset()\n",
    "    anti_set = train_set.build_anti_testset()\n",
    "    all_scores = pd.DataFrame(gs.test(all_set))\n",
    "    anti_scores = pd.DataFrame(gs.test(anti_set))\n",
    "    \n",
    "    all_scores[\"algorithm\"] = algo.__name__\n",
    "    anti_scores[\"algorithm\"] = algo.__name__    \n",
    "    \n",
    "    all_scores[\"score_type\"] = \"known\"\n",
    "    anti_scores[\"score_type\"] = \"anti\"        \n",
    "\n",
    "    all_scores[\"base\"] = base\n",
    "    anti_scores[\"base\"] = base        \n",
    "    \n",
    "    return (all_scores, anti_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLightFMModel(data, base, ratings, algo=\"LightFM\"):\n",
    "    \n",
    "    print(f\"\\n****** Training for LightFM model: {algo} with {base} data ...\\n\")\n",
    "\n",
    "    y1_sparse = coo_matrix(data.fillna(0).values, dtype = \"float32\")\n",
    "\n",
    "    model = LightFM(no_components=10, loss= \"warp\")\n",
    "\n",
    "    lt_train, lt_test = random_train_test_split(y1_sparse, 0.2)\n",
    "    model.fit(lt_train, epochs=20)\n",
    "    k = 7\n",
    "    precision = precision_at_k(model, lt_train, k=5).mean()\n",
    "    recall = recall_at_k(model, lt_train, k=5).mean()\n",
    "\n",
    "    print(f\"Precision@{k} :{precision}\")\n",
    "    print(f\"Recall@{k} :{recall}\")\n",
    "    \n",
    "    ## Refit with full data\n",
    "    model.fit(y1_sparse, epochs=20)\n",
    "    \n",
    "    predictions = np.zeros(shape=y1_sparse.shape)\n",
    "    cols = np.arange(y1_sparse.shape[1])\n",
    "    for i in range(y1_sparse.shape[0]):\n",
    "        predictions[i] = model.predict(i,cols)\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions,columns=data.columns, index=data.index )\n",
    "    predictions_df = predictions_df.stack().reset_index()\n",
    "    predictions_df.columns = [\"user_id\",\"product_id\",\"est\"]\n",
    "    predictions_df = pd.merge(predictions_df,ratings, on=[\"user_id\",\"product_id\"], how=\"left\")\n",
    "\n",
    "    predictions_df[\"score_type\"] = \"anti\"\n",
    "    predictions_df.loc[predictions_df.rating.notnull(), \"score_type\"] = \"known\"\n",
    "    predictions_df[\"algorithm\"] = algo\n",
    "    predictions_df[\"base\"] = base\n",
    "\n",
    "    predictions_df.columns = ['uid', 'iid'] + predictions_df.columns.tolist()[2:]\n",
    "    predictions_df = predictions_df[['uid', 'iid', 'rating', 'est', 'algorithm','score_type','base']]\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scoring_files():\n",
    "    mypath = \"../../data/output/algo/\"\n",
    "    from os import walk\n",
    "\n",
    "    all_scores = pd.DataFrame()\n",
    "    for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "        for filename in filenames:\n",
    "            print(f\"reading... {filename} \")\n",
    "            csv_file_name  = mypath + filename\n",
    "            df = pd.read_csv(csv_file_name)\n",
    "            print(f\"rows read : {df.shape[0]}\")\n",
    "            all_scores = all_scores.append(df)\n",
    "            print(f\"Combined rows so far : {all_scores.shape[0]}\")\n",
    "\n",
    "    file_name = \"../../data/output/all_reco_scores.csv\"\n",
    "    all_scores.to_csv(file_name,index=False)\n",
    "    all_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files_exist(data_path):\n",
    "    path_to_check = data_path\n",
    "    if not path.exists(path_to_check):\n",
    "        raise ValueError(f\"Path/file {path_to_check} does not exits\")\n",
    "    else:\n",
    "        print(f\"Valid file/path : {path_to_check}\")\n",
    "\n",
    "    path_to_check = data_path + \"processed/users.csv\"\n",
    "    if not path.exists(path_to_check):\n",
    "        raise ValueError(f\"Path/file {path_to_check} does not exits\")\n",
    "    else:\n",
    "        print(f\"Valid file/path : {path_to_check}\")\n",
    "\n",
    "    path_to_check = data_path + \"processed/items.csv\"\n",
    "    if not path.exists(path_to_check):\n",
    "        raise ValueError(f\"Path/file {path_to_check} does not exits\")\n",
    "    else:\n",
    "        print(f\"Valid file/path : {path_to_check}\")\n",
    "        \n",
    "    path_to_check = data_path + \"output/\"\n",
    "    if not path.exists(path_to_check):\n",
    "        print(f\"Creating folder {path_to_check}\")\n",
    "        os.makedirs(path_to_check)\n",
    "    else:\n",
    "        print(f\"Valid file/path : {path_to_check}\")\n",
    "\n",
    "    path_to_check = data_path + \"output/algo/\"\n",
    "    if not path.exists(path_to_check):\n",
    "        print(f\"Creating folder {path_to_check}\")\n",
    "        os.makedirs(path_to_check)\n",
    "    else:\n",
    "        print(f\"Valid file/path : {path_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid file/path : ../../data/\n",
      "Valid file/path : ../../data/processed/users.csv\n",
      "Valid file/path : ../../data/processed/items.csv\n",
      "Valid file/path : ../../data/output/\n",
      "Valid file/path : ../../data/output/algo/\n",
      "\n",
      "Generate unique products dataframe ...\n",
      "\n",
      "  brand_id product_id            item_name_lower product_category_id size  \\\n",
      "0     loft   62733a41  petite textured pencil pa         123 - Pants  NaN   \n",
      "1     loft   7ca9f965   blurred fairisle sweater         114 - Knits  NaN   \n",
      "2     loft   6273435d   lou grey eyelash sweater         114 - Knits  NaN   \n",
      "3     loft   62732b46  petite plaid pencil pants         123 - Pants  NaN   \n",
      "4     loft   627342fa  petite custom stretch tro         123 - Pants  NaN   \n",
      "\n",
      "   on_sale  price_bin  \n",
      "0    False          3  \n",
      "1    False          3  \n",
      "2    False          3  \n",
      "3    False          3  \n",
      "4    False          3  \n",
      "\n",
      "Generate interaction: user vs store-cat and user vs products...\n",
      "\n",
      "\n",
      "****** Training for Surprise model: SVD with store_cat data ...\n",
      "\n",
      "best RMSE score : 3.2491835532446074\n",
      "best MAE score : 1.646093604637281\n",
      "best parms for RMSE score : {'n_factors': 5, 'n_epochs': 10, 'lr_all': 0.010145226130653266, 'reg_all': 0.9696969696969697, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 5, 'n_epochs': 10, 'lr_all': 0.010145226130653266, 'reg_all': 0.9696969696969697, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: SVD with product data ...\n",
      "\n",
      "best RMSE score : 0.14360288448692723\n",
      "best MAE score : 0.036197175050163184\n",
      "best parms for RMSE score : {'n_factors': 10, 'n_epochs': 20, 'lr_all': 0.00311356783919598, 'reg_all': 0.8787878787878789, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 5, 'n_epochs': 80, 'lr_all': 0.00612713567839196, 'reg_all': 0.16161616161616163, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: SVDpp with store_cat data ...\n",
      "\n",
      "best RMSE score : 4.265098114681488\n",
      "best MAE score : 3.526233402059814\n",
      "best parms for RMSE score : {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.06338492462311558, 'reg_all': 0.020202020202020204, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 10, 'n_epochs': 10, 'lr_all': 0.06338492462311558, 'reg_all': 0.020202020202020204, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: SVDpp with product data ...\n",
      "\n",
      "best RMSE score : 0.1442653858254848\n",
      "best MAE score : 0.03505404582901528\n",
      "best parms for RMSE score : {'n_factors': 15, 'n_epochs': 20, 'lr_all': 0.00311356783919598, 'reg_all': 0.9090909090909092, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 5, 'n_epochs': 20, 'lr_all': 0.057357788944723626, 'reg_all': 0.04040404040404041, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: NMF with store_cat data ...\n",
      "\n",
      "best RMSE score : 3.1542915268021154\n",
      "best MAE score : 1.5448920585884396\n",
      "best parms for RMSE score : {'n_factors': 10, 'n_epochs': 10, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 5, 'n_epochs': 10, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: NMF with product data ...\n",
      "\n",
      "best RMSE score : 0.14528538937858826\n",
      "best MAE score : 0.03618500456456281\n",
      "best parms for RMSE score : {'n_factors': 20, 'n_epochs': 80, 'random_state': 35}\n",
      "best parms for MAE score : {'n_factors': 20, 'n_epochs': 80, 'random_state': 35}\n",
      "\n",
      "****** Training for Surprise model: KNNBasic with store_cat data ...\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 3.220689874982654\n",
      "best MAE score : 1.6769088347204661\n",
      "best parms for RMSE score : {'k': 10, 'sim_options': {'name': 'cosine', 'min_support': 3, 'user_based': False}}\n",
      "best parms for MAE score : {'k': 15, 'sim_options': {'name': 'cosine', 'min_support': 10, 'user_based': False}}\n",
      "\n",
      "****** Training for Surprise model: KNNBasic with product data ...\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 0.14407913340112619\n",
      "best MAE score : 0.03605772016176695\n",
      "best parms for RMSE score : {'k': 25, 'sim_options': {'name': 'cosine', 'min_support': 35, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 25, 'sim_options': {'name': 'cosine', 'min_support': 35, 'user_based': True}}\n",
      "\n",
      "****** Training for Surprise model: KNNWithMeans with store_cat data ...\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 3.241467399577283\n",
      "best MAE score : 1.6582316838833815\n",
      "best parms for RMSE score : {'k': 40, 'sim_options': {'name': 'cosine', 'min_support': 10, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 40, 'sim_options': {'name': 'cosine', 'min_support': 10, 'user_based': True}}\n",
      "\n",
      "****** Training for Surprise model: KNNWithMeans with product data ...\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 0.14492870433698382\n",
      "best MAE score : 0.03602822975425318\n",
      "best parms for RMSE score : {'k': 15, 'sim_options': {'name': 'cosine', 'min_support': 15, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 15, 'sim_options': {'name': 'cosine', 'min_support': 15, 'user_based': True}}\n",
      "\n",
      "****** Training for Surprise model: KNNWithZScore with store_cat data ...\n",
      "\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 3.239407025138094\n",
      "best MAE score : 1.6247567516588493\n",
      "best parms for RMSE score : {'k': 35, 'sim_options': {'name': 'cosine', 'min_support': 10, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 35, 'sim_options': {'name': 'cosine', 'min_support': 10, 'user_based': True}}\n",
      "\n",
      "****** Training for Surprise model: KNNWithZScore with product data ...\n",
      "\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 0.14480824413361373\n",
      "best MAE score : 0.03606472739199904\n",
      "best parms for RMSE score : {'k': 20, 'sim_options': {'name': 'msd', 'min_support': 1, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 5, 'sim_options': {'name': 'msd', 'min_support': 50, 'user_based': False}}\n",
      "\n",
      "****** Training for Surprise model: KNNBaseline with store_cat data ...\n",
      "\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 3.211999382666614\n",
      "best MAE score : 1.6476538538996592\n",
      "best parms for RMSE score : {'k': 15, 'sim_options': {'name': 'cosine', 'min_support': 40, 'user_based': True}}\n",
      "best parms for MAE score : {'k': 1, 'sim_options': {'name': 'cosine', 'min_support': 5, 'user_based': False}}\n",
      "\n",
      "****** Training for Surprise model: KNNBaseline with product data ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "best RMSE score : 0.1446834891325475\n",
      "best MAE score : 0.035666965768671906\n",
      "best parms for RMSE score : {'k': 5, 'sim_options': {'name': 'msd', 'min_support': 40, 'user_based': False}}\n",
      "best parms for MAE score : {'k': 5, 'sim_options': {'name': 'msd', 'min_support': 40, 'user_based': False}}\n",
      "\n",
      "****** Training for LightFM model: LightFM_Basic with store-cat data ...\n",
      "\n",
      "Precision@7 :0.5586956143379211\n",
      "Recall@7 :0.23119685245485805\n",
      "\n",
      "****** Training for LightFM model: LightFM_Basic with product data ...\n",
      "\n",
      "Precision@7 :0.758695662021637\n",
      "Recall@7 :0.22223338689514666\n",
      "reading... all_reco_scores_SVD.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 793941\n",
      "reading... all_reco_scores_KNNWithMeans.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 1587882\n",
      "reading... all_reco_scores_KNNBasic.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 2381823\n",
      "reading... all_reco_scores_LightFM_Basic.csv \n",
      "rows read : 793941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined rows so far : 3175764\n",
      "reading... all_reco_scores_KNNWithZScore.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 3969705\n",
      "reading... all_reco_scores_KNNBaseline.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 4763646\n",
      "reading... all_reco_scores_SVDpp.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 5557587\n",
      "reading... all_reco_scores_NMF.csv \n",
      "rows read : 793941\n",
      "Combined rows so far : 6351528\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\" Set Seeds, but seems we need to set the seed anyway for each algorithm\"\"\"\n",
    "    my_seed = 55\n",
    "    random.seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "\n",
    "    files_path = \"../../data/\"\n",
    "\n",
    "    check_files_exist(files_path)\n",
    "\n",
    "    \"\"\"Read item and user processed data\"\"\"\n",
    "    df_users = pd.read_csv(files_path + \"processed/users.csv\")\n",
    "    df_items = pd.read_csv(files_path + \"processed/items.csv\")\n",
    "    df_items.item_name_lower = df_items.item_name_lower.map(lambda x : x[:25])\n",
    "    products = get_unique_products(df_items)\n",
    "    x1,y1,x2,y2 = generate_interaction_files(df_items)\n",
    "\n",
    "    \"\"\" Run Surprise models \"\"\"\n",
    "    reader = Reader()\n",
    "    data1 = Dataset.load_from_df(x1,reader)\n",
    "    data2 = Dataset.load_from_df(x2,reader)\n",
    "\n",
    "    algorithms = [SVD, SVDpp, NMF, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline]\n",
    "    # algorithms = [SVD]\n",
    "\n",
    "    n_iterations = 10\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        all_s1, anti_s1 = trainSurpriseModel(data1, base=\"store_cat\", algo=algorithm, search_iteration= n_iterations)\n",
    "        all_s2, anti_s2 = trainSurpriseModel(data2, base=\"product\", algo=algorithm, search_iteration= n_iterations)\n",
    "        all_scores = all_s1.append(anti_s1).append(all_s2).append(anti_s2)\n",
    "        all_scores.drop(\"details\", axis=1, inplace=True)\n",
    "        file_name = files_path + \"output/algo/all_reco_scores_\" + algorithm.__name__ + \".csv\"\n",
    "        all_scores.to_csv(file_name,index=False)\n",
    "\n",
    "    \"\"\"Run LightFM Models\"\"\"\n",
    "    base = \"store-cat\"\n",
    "    algo_name = \"LightFM_Basic\"\n",
    "    all_scores = trainLightFMModel(y1,base,x1,algo=algo_name)\n",
    "    base = \"product\"\n",
    "    all_scores2 = trainLightFMModel(y2,base,x2,algo=algo_name)\n",
    "\n",
    "    all_scores = all_scores.append(all_scores2)\n",
    "    file_name = files_path + \"output/algo/all_reco_scores_\" + algo_name + \".csv\"\n",
    "    all_scores.to_csv(file_name,index=False)\n",
    "\n",
    "\n",
    "    \"\"\" Generate combined scoring file\"\"\"\n",
    "    combine_scoring_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
